{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8b1d6b",
   "metadata": {},
   "source": [
    "## 1. Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e5d9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install setuptools==58\n",
    "# pip install feedparser --upgrade\n",
    "# pip install pygooglenews\n",
    "# pip install vaderSentiment\n",
    "# !pip install newspaper3k --quiet\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e5fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ioncararus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from GoogleNews import GoogleNews\n",
    "from bs4 import BeautifulSoup\n",
    "from requests_html import HTMLSession\n",
    "# from pygooglenews import GoogleNews\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from newspaper import Article\n",
    "from newspaper import Config\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda62ef",
   "metadata": {},
   "source": [
    "## 2. Functions and parameters declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75069b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_pattern = \"//link[@rel='canonical']/@href\" # pattern to extract canonical url from html doc\n",
    "regex_pattern = r\".?([\\w\\-\\.]+)\" # regex pattern to get the domain of the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4016d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_to_df(*datasets):\n",
    "    \"\"\"\n",
    "    Input : strings of CSVs titles\n",
    "    Output: pandas dataframe containg all records in all CSVs\n",
    "    \"\"\"\n",
    "    df_list = [pd.read_csv(dataset) for dataset in datasets]\n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d36262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sent_analysis(text):\n",
    "    \"\"\"\n",
    "    Input: text\n",
    "    Output: value compound sentiment\n",
    "    \"\"\"\n",
    "    sa = SentimentIntensityAnalyzer()\n",
    "    dict_sa = sa.polarity_scores(text)\n",
    "    return dict_sa['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cdcc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(filepath,filename):        \n",
    "    with open(filepath+filename,\"r\") as f:\n",
    "        return [line for count, line in enumerate(f) if 'support.google' not in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8577504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_sentiment(links_list):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        list of URLs\n",
    "    Description:\n",
    "        reads URL article and retrieves keywords, summary, text, and calculates sentiment of the summary\n",
    "    Output:\n",
    "        pandas DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {'url':[],'keywords':[],'summary':[],'text':[],'sentiment':[]}\n",
    "    config = Config()\n",
    "    config.browser_user_agent = USER_AGENT\n",
    "#     config.request_timeout = 10\n",
    "    for link in links_list:\n",
    "        try:\n",
    "            article = Article(link, config=config)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "\n",
    "            article.nlp()\n",
    "            text = article.text\n",
    "            summary = article.summary\n",
    "            keywords = article.keywords\n",
    "            keywords.sort()\n",
    "\n",
    "            article = None\n",
    "            \n",
    "            _ = re.findall(regex_pattern, link)[1]\n",
    "            data['url'].append(_)\n",
    "            data['keywords'].append(keywords)\n",
    "            data['summary'].append(summary)\n",
    "            data['text'].append(text)\n",
    "            data['sentiment'].append(run_sent_analysis(summary))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0be7e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_analyzed_df(dfa, n):\n",
    "    df = None\n",
    "    for i in range(n):\n",
    "        if i==0:\n",
    "            links_list = get_links(r\"/Users/ioncararus/Downloads/politicians/\", f\"pol_{i}.txt\")\n",
    "            df = get_article_sentiment(links_list)\n",
    "            df['name'] = dfa.loc[i,'name']\n",
    "        else:\n",
    "            links_list = get_links(r\"/Users/ioncararus/Downloads/politicians/\", f\"pol_{i}.txt\")\n",
    "            _df = get_article_sentiment(links_list)\n",
    "            _df['name']=dfa.loc[i,'name']\n",
    "            df = pd.concat([df,_df], ignore_index=True)\n",
    "        if i%50==0:\n",
    "            print(i, end = '\\n')\n",
    "        else:\n",
    "            print(i, end = ' ')\n",
    "    df.to_csv('sentiment.csv', sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac8bb7a",
   "metadata": {},
   "source": [
    "### Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224074c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_members = load_all_to_df(\"term-116_congress.csv\",\"term-116_senate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "979e6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_members_sentiment = return_analyzed_df(df_members, df_members.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb81a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd258742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f121a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
